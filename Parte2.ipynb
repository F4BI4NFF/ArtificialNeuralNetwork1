{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation from Scratch\n",
    "\n",
    "En esta sección se trabajará con los algoritmos que resuelven las redes neuronales *Feed Forward*, es decir, los algoritmos que encuentran valores óptimos para sus pesos. Para esto se implementará estos algoritmos desde 0 (*from scratch*) teniendo unicamente el apoyo de librerías para operaciones básicas como lo entrega **numpy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Entrenar una red **FF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.,  0.],\n",
      "       [ 0.,  0.],\n",
      "       [ 0.,  0.]]), array([[ 0.],\n",
      "       [ 0.]])]\n",
      "[ 2  5 11]\n",
      "[ 0.5  0.5]\n",
      "[ 0.5]\n",
      "2\n",
      "back\n",
      "[array([[-0.375 , -0.375 ],\n",
      "       [-0.9375, -0.9375],\n",
      "       [-2.0625, -2.0625]]), array([[-0.09375],\n",
      "       [-0.09375]])]\n"
     ]
    }
   ],
   "source": [
    "#pasos inicializadores\n",
    "#L = 3 #numero de capas (IMPORTANTE)\n",
    "#S, A, A_der,E_salida,E_pesos = crear_arquitectura(3,2,3)\n",
    "#WM = init(L,S)\n",
    "FF = red_neuronal([3,3,2,1])\n",
    "print FF.WM\n",
    "\n",
    "xi = np.array([2,5,11])\n",
    "yi = 2\n",
    "forward_pass(xi,yi,FF.L,FF.WM, FF.A,FF.A_der,FF.S)\n",
    "print FF.A[FF.L-3]\n",
    "print FF.A[FF.L-2]\n",
    "print FF.A[FF.L-1]\n",
    "print yi\n",
    "\n",
    "print \"back\"\n",
    "backward_pass(xi,yi,FF.L,FF.WM,FF.A,FF.A_der,FF.S,FF.E_salida,FF.E_pesos)\n",
    "print FF.WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola mundo\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "epsilon =  1e-15\n",
    "\n",
    "#----funcion de activacion y gradiente\n",
    "def sigmoid(x):\n",
    "    x = np.maximum(epsilon, x) #si x es muy pequeño\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "        \n",
    "def gradient_sigmoid(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "#---funcion de perdida y gradiente\n",
    "def loss_function(y,ypred):\n",
    "    #binary\n",
    "    ypred = np.maximum(epsilon, ypred)\n",
    "    return -1.0*( y*np.log(ypred) + np.subtract(1,y)*np.log(np.subtract(1,ypred)) ) \n",
    "\n",
    "    #error cuadratico\n",
    "    #return np.pow(y-ypred,2)/2\n",
    "def gradient_loss_function(y,ypred):\n",
    "    #binary\n",
    "    ypred = np.maximum(epsilon, ypred)\n",
    "    return -1.0* ( y-ypred)/(ypred*np.subtract(1,ypred))\n",
    "    \n",
    "    #error cuadratico\n",
    "    #return y-ypred\n",
    "\n",
    "#funcion que crea la arquitectura y crea las matrices \n",
    "#necesarias para almacenar informacion\n",
    "def crear_arquitectura(input_dim,H,O,L):\n",
    "    # numero de neuronas por capa\n",
    "    S = range(L)\n",
    "    S[0] = input_dim #input\n",
    "    S[1] = H #oculta\n",
    "    S[2] = O #salida\n",
    "    \n",
    "    #inicializan matrices de salidas de neuronas\n",
    "    A = range(L)\n",
    "    A_der = range(L) \n",
    "    for l in range(0,L):\n",
    "        A[l] = np.zeros(S[l]) #salida de capa l\n",
    "        A_der[l] = A[l].copy()       #salida derivada de capa l\n",
    "        \n",
    "    #inicializa matrices que guardan derividas\n",
    "    Error_salida = range(L)\n",
    "    Error_peso = range(L)\n",
    "    for l in range(0,L):\n",
    "        Error_salida[l] = np.zeros(S[l]) # error salida de capa l\n",
    "    for l in range(0,L-1):\n",
    "        Error_peso[l] = np.zeros((S[l],S[l+1]))    \n",
    "        \n",
    "    return S,A,A_der, Error_salida, Error_peso\n",
    "\n",
    "##### S es una lista\n",
    "##### A y A_der es lista de arrays numpy\n",
    "## A[l][s] la salida de la neurona \"s\" en la capa \"l\"\n",
    "##### WM es lista de matrices \n",
    "## WM[l][s:,] los pesos de los valores que salen de la neurona \"s\" de la capa \"l\"\n",
    "#### Error son listas de matrices que guardan las derivadas del error\n",
    "#funcion de salida\n",
    "#funcion de pesos\n",
    "#Error[l][s] #capa l, neurona s\n",
    "\n",
    "#inicializa pesos\n",
    "def init(L,S): \n",
    "    WM = range(L-1)\n",
    "    for l in range(0,L-1):\n",
    "        WM[l] = np.zeros((S[l],S[l+1]))\n",
    "    return WM  \n",
    "\n",
    "#realiza un forward pass de un par (xi,yi)\n",
    "def forward_pass(xi,yi,L,WM, A,A_der,S):\n",
    "    A[0] = xi #inicializa el input\n",
    "    for l in range(0,L-1): #por cada capa        \n",
    "        for s in range(0,S[l+1]): #por cada neurona de la capa siguiente\n",
    "            aux = np.dot( WM[l][:,s], A[l])\n",
    "            A[l+1][s] = sigmoid(aux)\n",
    "            A_der[l+1][s] = gradient_sigmoid(aux)\n",
    "\n",
    "def backward_pass(xi,yi,L,WM,A,A_der,S, Error_salida,Error_peso,lr):\n",
    "    #calcula el error en la ultima capa\n",
    "    for s in range(0,S[L-1]): \n",
    "        if S[L-1] == 1: #una salida\n",
    "            ypred = A[L-1][0]\n",
    "            Error_salida[L-1][0] = gradient_loss_function(yi, ypred)\n",
    "            Error_peso[L-2][:,0] = Error_salida[L-1][0] * (A_der[L-1][0] * A[L-2][0] )\n",
    "        else:#arquitectura con multiples salidas\n",
    "            ypred = A[L-1].copy()\n",
    "            Error_salida[L-1][s] = gradient_loss_function(yi[s], ypred[s]) #para el caso en que sea vector\n",
    "            Error_peso[L-2][:,s] = Error_salida[L-1][s] * (A_der[L-1][s] * A[L-2])\n",
    "        #actualizar pesos en vector\n",
    "        WM[L-2][:,s] = WM[L-2][:,s] - lr*Error_peso[L-2][:,s]\n",
    "        \n",
    "    #calcula el error recurisvamente\n",
    "    for l in np.arange(L-2,0,-1): #desde la penultima capa hasta la segunda {L-2,1}\n",
    "        for s in range(0,S[l]): #para cada neurona en la capa l\n",
    "            Error_salida[l][s] = np.sum(Error_salida[l+1])\n",
    "            Error_peso[l-1][:,s] =  Error_salida[l][s] * ( A_der[l][s] * A[l-1])\n",
    "            \n",
    "            #actualizar pesos en vector\n",
    "            WM[l-1][:,s] = WM[l-1][:,s] - lr*Error_peso[l-1][:,s]\n",
    "\n",
    "#estructura de red neuronal con sus atributos necesarios\n",
    "class red_neuronal:\n",
    "    def __init__(self,args):\n",
    "        self.L = args[0]\n",
    "        self.input_dim = args[1]\n",
    "        self.H = args[2]\n",
    "        self.O = args[3]\n",
    "        self.S, self.A, self.A_der,self.E_salida,self.E_pesos = crear_arquitectura(\n",
    "                                                                    self.input_dim,\n",
    "                                                                    self.H,\n",
    "                                                                    self.O,\n",
    "                                                                    self.L\n",
    "                                                                    )\n",
    "        self.WM = init(self.L,self.S)          \n",
    "        \n",
    "    def entrenar(self,X,Y,lr,epochs):\n",
    "        error_por_epoch = []\n",
    "        for i in range(epochs): #criterio de parada\n",
    "            error = []\n",
    "            for xi,yi in zip(X,Y): #con sgd un ejemplo a la vez\n",
    "                #actualizan las salidas\n",
    "                forward_pass(xi,yi,self.L,self.WM, self.A,self.A_der,self.S)\n",
    "                \n",
    "                #medir el error\n",
    "                ypred = self.A[self.L-1].copy()\n",
    "                error.append(loss_function(yi,ypred))\n",
    "\n",
    "                #actualizan los pesos\n",
    "                backward_pass(xi,yi,self.L,self.WM,self.A,self.A_der,self.S,self.E_salida,self.E_pesos,lr)\n",
    "            error_por_epoch.append( np.mean(error) )\n",
    "        return error_por_epoch\n",
    "                  \n",
    "print \"hola mundo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cambiaon los indices ya que parto desde la capa 0, no 1\n",
    "\n",
    "hablar de todos los argumentos de las funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Predicciones con la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#FF  = red ya entrenada\n",
    "def predecir(X_test,y_test,FF):\n",
    "    n_test = len(y_test)\n",
    "    print \"numero de ejemplos: \",n_test\n",
    "    \n",
    "    predicciones = []\n",
    "    for xi,yi in zip(X_test,y_test): #para n_test ejemplos\n",
    "        y_hat = forward_pass(xi,yi,FF.L,FF.WM, FF.A,FF.A_der,FF.S)\n",
    "        predicciones.append(y_hat)\n",
    "    return predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Probar programa creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 7)\n",
      "(210,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt'\n",
    "df = pd.read_csv(url, sep=r'\\s+',header=None)\n",
    "X_train = df.ix[:,0:6]\n",
    "y_train = df.ix[:,7]\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset sobre el cual se probará el programa de una red neuronal *Feed Forward* es el de **seeds**, la tarea consta de clasificar un ejemplo como un tipo de semilla en específico (3 clases). Se consta de 7 atributos para lograr identificar a cuál tipo de semilla pertenece. La cantidad de ejemplos son 210."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    retorno = np.zeros(len(x))\n",
    "    suma =0.0\n",
    "    for i in x:\n",
    "        suma+=np.exp(i)\n",
    "    for i in range(len(x)):\n",
    "        retorno[i] = np.exp(x[i])/suma\n",
    "    return retorno\n",
    "def gradient_softmax(x):\n",
    "    return softmax(x)*(1-softmax(x))\n",
    "\n",
    "def forward_pass(xi,yi,L,WM, A,A_der,S):\n",
    "    A[0] = xi #inicializa el input\n",
    "    for l in range(0,L-1): #por cada capa        \n",
    "        for s in range(0,S[l+1]): #por cada neurona de la capa siguiente\n",
    "            aux = np.dot( WM[l][:,s], A[l])\n",
    "            A[l+1][s] = sigmoid(aux)\n",
    "            A_der[l+1][s] = gradient_sigmoid(aux)\n",
    "    A[L-1] = softmax(A[L-1])\n",
    "    return A[L-1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se añade la función de activación softmax a la última capa debido a que el problema de multiclases lo amerita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 3)\n"
     ]
    }
   ],
   "source": [
    "#y en un hot vector\n",
    "nuevo_df = pd.get_dummies(df,columns =[7])\n",
    "casi_y = nuevo_df.ix[:,7:10]\n",
    "y_hotvector = np.asarray(casi_y)\n",
    "print y_hotvector.shape\n",
    "\n",
    "#Creacion de la red FF\n",
    "L = 3\n",
    "input_dim = X_train.shape[1]\n",
    "H = 32 #hidden\n",
    "O = 3 #outpit\n",
    "FF = red_neuronal([L,input_dim,H,O])\n",
    "errores = FF.entrenar(X_train,y_hotvector,lr = 0.1 ,epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior se entrena la red creada con 3 capas, 32 neuronas en la capa escondida y 3 neuronas en la capa de salida debido a que el problema es un problema de clasificación de 3 clases. La función de activación seleccionada anteriormente es la sigmoidal, esencial para problemas de clasificación. La función de pérdida es la ...\n",
    "Se entrena la red con *learning rate* de ... y número de epochs ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero de ejemplos:  210\n",
      "[array([ 0.23687835,  0.39050865,  0.372613  ]), array([ 0.23291315,  0.38400886,  0.38307799]), array([ 0.23291315,  0.38400886,  0.38307799]), array([ 0.23291315,  0.38400886,  0.38307799]), array([ 0.23687835,  0.39050865,  0.372613  ])]\n"
     ]
    }
   ],
   "source": [
    "print predecir(X_train,y_hotvector ,FF)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda anterior se prueba que el programa anterior creado para hacer prediciones con la red neuronal creada funciona, entregando una predicción para cada valor del conjunto requerido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtgAAAGJCAYAAACw6UTKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3da59286d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Binary Cross entropy Error\")\n",
    "plt.plot(np.arange(1,101),errores)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0.3,0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "asdasd la funcion obj es la misma que el error presentado, ya que no existe regularizacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### d) weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#idea..\n",
    "WM[l-1][:,s] = weight_decay * WM[l-1][:,s] - lr*Error_peso[l-1][:,s]\n",
    "#actualizar weight decay"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
